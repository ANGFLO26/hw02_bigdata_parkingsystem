# PHÃ‚N TÃCH Váº¤N Äá»€ - MÃY 3 KHÃ”NG THá»‚ VISUALIZATION

## ğŸ” TÃ“M Táº®T Váº¤N Äá»€

MÃ¡y 1 Ä‘Ã£ gá»­i dá»¯ liá»‡u lÃªn `parking-raw-events` nhÆ°ng mÃ¡y 3 khÃ´ng thá»ƒ visualization vÃ¬ khÃ´ng cÃ³ dá»¯ liá»‡u trong `parking-processed-results`. Váº¥n Ä‘á» náº±m á»Ÿ **MÃY 2 (Spark Processor)**.

---

## ğŸ› CÃC Váº¤N Äá»€ ÄÃƒ PHÃT HIá»†N

### âŒ Váº¤N Äá»€ 1: Lá»—i trong Spark StatefulProcessor

**Lá»—i trong log:**
```
pyspark.errors.exceptions.base.PySparkValueError: Invalid return type. 
Please make sure that the UDF returns a pandas.DataFrame when the specified return type is StructType.
```

**NguyÃªn nhÃ¢n:**
- HÃ m `handleExpiredTimer()` tráº£ vá» `pd.DataFrame()` (DataFrame rá»—ng khÃ´ng cÃ³ schema) á»Ÿ dÃ²ng 334 vÃ  348
- Spark yÃªu cáº§u DataFrame pháº£i cÃ³ Ä‘Ãºng schema ngay cáº£ khi rá»—ng

**Vá»‹ trÃ­:** `may2_kafka_spark/spark_processor.py`
- DÃ²ng 334: `return pd.DataFrame()`
- DÃ²ng 348: `return pd.DataFrame()`

---

### âŒ Váº¤N Äá»€ 2: startingOffsets="latest"

**Váº¥n Ä‘á»:**
- Spark Ä‘Æ°á»£c cáº¥u hÃ¬nh vá»›i `startingOffsets="latest"` (dÃ²ng 439)
- Náº¿u Spark khá»Ÿi Ä‘á»™ng **SAU** khi mÃ¡y 1 Ä‘Ã£ gá»­i dá»¯ liá»‡u, Spark sáº½ **KHÃ”NG Äá»ŒC** Ä‘Æ°á»£c dá»¯ liá»‡u cÅ©
- Spark chá»‰ Ä‘á»c dá»¯ liá»‡u má»›i tá»« thá»i Ä‘iá»ƒm khá»Ÿi Ä‘á»™ng

**Vá»‹ trÃ­:** `may2_kafka_spark/spark_processor.py` dÃ²ng 439

**Giáº£i phÃ¡p:** Äá»•i thÃ nh `"earliest"` Ä‘á»ƒ Ä‘á»c tá»« Ä‘áº§u topic, hoáº·c dÃ¹ng `"latest"` chá»‰ khi cháº¯c cháº¯n Spark khá»Ÿi Ä‘á»™ng trÆ°á»›c mÃ¡y 1

---

### âš ï¸ Váº¤N Äá»€ 3: DataFrame trong handleExpiredTimer khÃ´ng Ä‘áº£m báº£o schema

**Váº¥n Ä‘á»:**
- DÃ²ng 388: `return pd.DataFrame([output_row])` cÃ³ thá»ƒ khÃ´ng cÃ³ Ä‘Ãºng dtypes
- Cáº§n Ä‘áº£m báº£o DataFrame cÃ³ Ä‘Ãºng schema nhÆ° `handleInputRows`

---

## ğŸ”§ CÃC BÆ¯á»šC Sá»¬A CHá»®A

### BÆ°á»›c 1: Sá»­a hÃ m handleExpiredTimer

**Thay Ä‘á»•i:**
1. Táº¡o helper function Ä‘á»ƒ táº¡o DataFrame rá»—ng vá»›i Ä‘Ãºng schema
2. Äáº£m báº£o táº¥t cáº£ DataFrame tráº£ vá» Ä‘á»u cÃ³ Ä‘Ãºng schema vÃ  dtypes

### BÆ°á»›c 2: Sá»­a startingOffsets

**Thay Ä‘á»•i:**
- Äá»•i tá»« `"latest"` sang `"earliest"` Ä‘á»ƒ Ä‘á»c Ä‘Æ°á»£c dá»¯ liá»‡u cÅ©
- Hoáº·c thÃªm tham sá»‘ Ä‘á»ƒ cÃ³ thá»ƒ chá»n

### BÆ°á»›c 3: Kiá»ƒm tra láº¡i

**Sau khi sá»­a:**
1. XÃ³a checkpoint cÅ© (náº¿u cÃ³)
2. Khá»Ÿi Ä‘á»™ng láº¡i Spark processor
3. Kiá»ƒm tra log xem cÃ³ lá»—i khÃ´ng
4. Kiá»ƒm tra topic `parking-processed-results` cÃ³ dá»¯ liá»‡u khÃ´ng

---

## ğŸ“‹ CÃC Lá»†NH CHáº Y CHO Tá»ªNG MÃY

### MÃY 2: Kafka Broker + Spark Processor

#### 1. Khá»Ÿi Ä‘á»™ng Kafka
```bash
cd may2_kafka_spark
./start_kafka.sh
```

#### 2. Táº¡o Topics (náº¿u chÆ°a cÃ³)
```bash
cd may2_kafka_spark
./create_topics.sh
```

#### 3. Cháº¡y Spark Processor
```bash
cd may2_kafka_spark

# XÃ³a checkpoint cÅ© (náº¿u cáº§n)
rm -rf /tmp/parking-checkpoint

# Cháº¡y Spark
./run_spark_server.sh
```

Hoáº·c cháº¡y thá»§ cÃ´ng:
```bash
cd may2_kafka_spark
# LÆ°u Ã½: Spark 4.0.1 Ä‘Ã£ cÃ³ sáºµn Kafka connector, khÃ´ng cáº§n --packages
spark-submit \
  --master local[*] \
  --executor-memory 2g \
  --executor-cores 2 \
  spark_processor.py \
  --kafka-bootstrap localhost:9092 \
  --input-topic parking-raw-events \
  --output-topic parking-processed-results \
  --checkpoint /tmp/parking-checkpoint
```

---

### MÃY 1: Simulator

```bash
cd may1_simulator

# Cháº¡y simulator
python parking_simulator.py \
  --kafka-bootstrap <IP_MÃY_2>:9092 \
  --topic parking-raw-events \
  --duration 30 \
  --interval 3.0
```

**VÃ­ dá»¥:**
```bash
python parking_simulator.py \
  --kafka-bootstrap 10.38.11.118:9092 \
  --topic parking-raw-events \
  --duration 30 \
  --interval 3.0
```

---

### MÃY 3: Visualization

```bash
cd may3_visualization

# Cháº¡y Streamlit
streamlit run visualization.py
```

**Sau Ä‘Ã³:**
1. Má»Ÿ trÃ¬nh duyá»‡t táº¡i `http://localhost:8501`
2. Trong sidebar:
   - **Kafka Bootstrap Servers**: `<IP_MÃY_2>:9092` (vÃ­ dá»¥: `10.38.11.118:9092`)
   - **Kafka Topic**: `parking-processed-results`
3. Nháº¥n nÃºt **"ğŸ”„ Káº¿t ná»‘i/Khá»Ÿi Ä‘á»™ng láº¡i"**

---

## ğŸ” KIá»‚M TRA VÃ€ DEBUG

### Kiá»ƒm tra Kafka Topics cÃ³ dá»¯ liá»‡u khÃ´ng

**TrÃªn MÃ¡y 2:**
```bash
# Kiá»ƒm tra topic input
/home/phanvantai/Downloads/kafka_2.13-3.7.0/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic parking-raw-events \
  --from-beginning \
  --max-messages 10

# Kiá»ƒm tra topic output
/home/phanvantai/Downloads/kafka_2.13-3.7.0/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic parking-processed-results \
  --from-beginning \
  --max-messages 10
```

### Kiá»ƒm tra Spark UI

Má»Ÿ trÃ¬nh duyá»‡t: `http://localhost:4040`

Kiá»ƒm tra:
- [ ] Streaming query Ä‘ang cháº¡y
- [ ] Input rate > 0 (Ä‘ang nháº­n dá»¯ liá»‡u)
- [ ] Output rate > 0 (Ä‘ang gá»­i dá»¯ liá»‡u)
- [ ] KhÃ´ng cÃ³ lá»—i trong "Failed Jobs"

### Kiá»ƒm tra Log Spark

```bash
# Xem log má»›i nháº¥t
cd may2_kafka_spark/logs
tail -f spark_processor_*.log
```

---

## âœ… THá»¨ Tá»° KHá»I Äá»˜NG ÄÃšNG

1. **MÃ¡y 2**: Khá»Ÿi Ä‘á»™ng Kafka â†’ Táº¡o topics â†’ Cháº¡y Spark Processor
2. **MÃ¡y 3**: Cháº¡y Streamlit â†’ Cáº¥u hÃ¬nh Kafka â†’ Káº¿t ná»‘i
3. **MÃ¡y 1**: Cháº¡y Simulator

**LÆ°u Ã½:** MÃ¡y 2 pháº£i khá»Ÿi Ä‘á»™ng Spark Processor **TRÆ¯á»šC** mÃ¡y 1 Ä‘á»ƒ Ä‘áº£m báº£o Spark Ä‘á»c Ä‘Æ°á»£c táº¥t cáº£ dá»¯ liá»‡u (náº¿u dÃ¹ng `startingOffsets="latest"`). Hoáº·c dÃ¹ng `"earliest"` Ä‘á»ƒ Ä‘á»c tá»« Ä‘áº§u.

---

## ğŸ“ GHI CHÃš

- Náº¿u Spark Ä‘Ã£ cháº¡y vá»›i checkpoint cÅ©, cÃ³ thá»ƒ cáº§n xÃ³a checkpoint Ä‘á»ƒ reset
- Kiá»ƒm tra firewall náº¿u káº¿t ná»‘i tá»« xa
- Äáº£m báº£o Kafka Ä‘ang cháº¡y trÆ°á»›c khi cháº¡y Spark
- Kiá»ƒm tra log Ä‘á»ƒ xem lá»—i chi tiáº¿t

