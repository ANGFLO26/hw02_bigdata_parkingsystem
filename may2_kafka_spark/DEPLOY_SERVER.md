# H∆Ø·ªöNG D·∫™N DEPLOY SPARK L√äN SERVER

## ‚úÖ X√ÅC NH·∫¨N

Code Spark hi·ªán t·∫°i **HO√ÄN TO√ÄN C√ì TH·ªÇ** ch·∫°y b·∫±ng `spark-submit` tr√™n server v√¨:
- ‚úÖ C√≥ h√†m `main()` v√† `if __name__ == "__main__"`
- ‚úÖ S·ª≠ d·ª•ng argparse ƒë·ªÉ nh·∫≠n arguments
- ‚úÖ Kh√¥ng c√≥ hardcode paths (checkpoint c√≥ th·ªÉ config qua argument)
- ‚úÖ S·ª≠ d·ª•ng Spark Structured Streaming (ph√π h·ª£p v·ªõi cluster)

---

## C√ÅCH CH·∫†Y TR√äN SERVER

### 1. Local Mode (Tr√™n c√πng m√°y v·ªõi Kafka)

```bash
cd may2_kafka_spark

spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:4.0.1 \
  --master local[*] \
  spark_processor.py \
  --kafka-bootstrap localhost:9092 \
  --input-topic parking-raw-events \
  --output-topic parking-processed-results \
  --checkpoint /tmp/parking-checkpoint
```

### 2. Standalone Cluster Mode

```bash
spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:4.0.1 \
  --master spark://<SPARK_MASTER_HOST>:7077 \
  --deploy-mode client \
  --executor-memory 2g \
  --executor-cores 2 \
  --total-executor-cores 4 \
  spark_processor.py \
  --kafka-bootstrap <KAFKA_BROKER_IP>:9092 \
  --input-topic parking-raw-events \
  --output-topic parking-processed-results \
  --checkpoint hdfs://<HDFS_NAMENODE>:9000/parking-checkpoint
```

**V√≠ d·ª• c·ª• th·ªÉ:**
```bash
spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:4.0.1 \
  --master spark://192.168.1.100:7077 \
  --deploy-mode client \
  --executor-memory 2g \
  --executor-cores 2 \
  spark_processor.py \
  --kafka-bootstrap 192.168.1.100:9092 \
  --input-topic parking-raw-events \
  --output-topic parking-processed-results \
  --checkpoint hdfs://192.168.1.100:9000/parking-checkpoint
```

### 3. YARN Cluster Mode

```bash
spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:4.0.1 \
  --master yarn \
  --deploy-mode cluster \
  --executor-memory 2g \
  --executor-cores 2 \
  --num-executors 2 \
  spark_processor.py \
  --kafka-bootstrap <KAFKA_BROKER_IP>:9092 \
  --input-topic parking-raw-events \
  --output-topic parking-processed-results \
  --checkpoint hdfs://<HDFS_NAMENODE>:9000/parking-checkpoint
```

### 4. Ch·∫°y Background (nohup)

```bash
nohup spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:4.0.1 \
  --master local[*] \
  spark_processor.py \
  --kafka-bootstrap localhost:9092 \
  --input-topic parking-raw-events \
  --output-topic parking-processed-results \
  --checkpoint /tmp/parking-checkpoint \
  > spark_processor.log 2>&1 &

# L∆∞u PID ƒë·ªÉ c√≥ th·ªÉ kill sau
echo $! > spark_processor.pid
```

---

## C·∫§U H√åNH QUAN TR·ªåNG KHI CH·∫†Y TR√äN SERVER

### 1. Checkpoint Location ‚ö†Ô∏è QUAN TR·ªåNG

**V·∫•n ƒë·ªÅ:** 
- Local mode: C√≥ th·ªÉ d√πng `/tmp/parking-checkpoint`
- Cluster mode: **PH·∫¢I** d√πng shared storage (HDFS, S3, NFS)

**Gi·∫£i ph√°p:**

#### Local Mode:
```bash
--checkpoint /tmp/parking-checkpoint
# ho·∫∑c
--checkpoint /opt/spark/checkpoints/parking
```

#### Cluster Mode (Standalone/YARN):
```bash
# HDFS (khuy·∫øn ngh·ªã)
--checkpoint hdfs://namenode:9000/parking-checkpoint

# S3 (n·∫øu d√πng AWS)
--checkpoint s3://bucket-name/parking-checkpoint

# NFS/Shared Storage
--checkpoint /mnt/shared/parking-checkpoint
```

**L√Ω do:** 
- Trong cluster mode, executors ch·∫°y tr√™n nhi·ªÅu nodes
- C·∫ßn shared storage ƒë·ªÉ:
  - L∆∞u state (stateful processing)
  - Recovery khi restart
  - ƒê·∫£m b·∫£o consistency gi·ªØa c√°c nodes

**Ki·ªÉm tra HDFS:**
```bash
# T·∫°o th∆∞ m·ª•c checkpoint tr√™n HDFS
hdfs dfs -mkdir -p /parking-checkpoint

# Ki·ªÉm tra quy·ªÅn
hdfs dfs -ls /parking-checkpoint
```

### 2. Kafka Bootstrap Servers

**V·∫•n ƒë·ªÅ:** Spark c·∫ßn k·∫øt n·ªëi ƒë·∫øn Kafka broker

**Gi·∫£i ph√°p:**
- N·∫øu Kafka v√† Spark tr√™n c√πng network: d√πng internal IP
- N·∫øu Kafka tr√™n network kh√°c: c·∫•u h√¨nh `advertised.listeners` trong Kafka
- Ki·ªÉm tra firewall: port 9092 ph·∫£i m·ªü

**Ki·ªÉm tra k·∫øt n·ªëi:**
```bash
# T·ª´ Spark node, ki·ªÉm tra k·∫øt n·ªëi ƒë·∫øn Kafka
telnet <KAFKA_BROKER_IP> 9092

# Ho·∫∑c
nc -zv <KAFKA_BROKER_IP> 9092
```

### 3. Spark Packages (Kafka Connector)

**V·∫•n ƒë·ªÅ:** Kafka connector c·∫ßn ƒë∆∞·ª£c load

**Gi·∫£i ph√°p 1: T·ª± ƒë·ªông download (khuy·∫øn ngh·ªã)**
```bash
--packages org.apache.spark:spark-sql-kafka-0-10_2.12:4.0.1
```

**Gi·∫£i ph√°p 2: Copy JAR th·ªß c√¥ng**
```bash
# Download JAR
wget https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/4.0.1/spark-sql-kafka-0-10_2.12-4.0.1.jar

# Copy v√†o Spark jars directory
cp spark-sql-kafka-0-10_2.12-4.0.1.jar $SPARK_HOME/jars/

# Sau ƒë√≥ ch·∫°y kh√¥ng c·∫ßn --packages
spark-submit \
  --master local[*] \
  spark_processor.py \
  ...
```

### 4. Memory v√† Resources

**C·∫•u h√¨nh ƒë·ªÅ xu·∫•t:**

```bash
# Local mode (single machine)
--executor-memory 2g
--executor-cores 2

# Cluster mode (production)
--executor-memory 4g
--executor-cores 4
--num-executors 3
--driver-memory 2g
```

### 5. Dependencies (Pandas)

**L∆∞u √Ω:** 
- Pandas ƒë√£ ƒë∆∞·ª£c Spark t·ª± ƒë·ªông include khi d√πng `transformWithStateInPandas`
- Kh√¥ng c·∫ßn c√†i th√™m n·∫øu d√πng Spark 4.0.1
- Code kh√¥ng c·∫ßn pandas trong requirements.txt v√¨ Spark t·ª± qu·∫£n l√Ω

---

## SCRIPT CH·∫†Y TR√äN SERVER

T·∫°o file `run_spark_server.sh`:

```bash
#!/bin/bash

# C·∫•u h√¨nh
SPARK_MASTER=${SPARK_MASTER:-"local[*]"}
KAFKA_BOOTSTRAP=${KAFKA_BOOTSTRAP:-"localhost:9092"}
CHECKPOINT=${CHECKPOINT:-"/tmp/parking-checkpoint"}
INPUT_TOPIC=${INPUT_TOPIC:-"parking-raw-events"}
OUTPUT_TOPIC=${OUTPUT_TOPIC:-"parking-processed-results"}

# Log file
LOG_FILE="spark_processor_$(date +%Y%m%d_%H%M%S).log"

echo "Starting Spark Processor..."
echo "Spark Master: $SPARK_MASTER"
echo "Kafka Bootstrap: $KAFKA_BOOTSTRAP"
echo "Checkpoint: $CHECKPOINT"
echo "Log file: $LOG_FILE"

spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:4.0.1 \
  --master $SPARK_MASTER \
  --executor-memory 2g \
  --executor-cores 2 \
  spark_processor.py \
  --kafka-bootstrap $KAFKA_BOOTSTRAP \
  --input-topic $INPUT_TOPIC \
  --output-topic $OUTPUT_TOPIC \
  --checkpoint $CHECKPOINT \
  2>&1 | tee $LOG_FILE
```

**S·ª≠ d·ª•ng:**
```bash
chmod +x run_spark_server.sh

# Ch·∫°y v·ªõi c·∫•u h√¨nh m·∫∑c ƒë·ªãnh
./run_spark_server.sh

# Ch·∫°y v·ªõi c·∫•u h√¨nh t√πy ch·ªânh
SPARK_MASTER="spark://192.168.1.100:7077" \
KAFKA_BOOTSTRAP="192.168.1.100:9092" \
CHECKPOINT="hdfs://192.168.1.100:9000/parking-checkpoint" \
./run_spark_server.sh
```

---

## MONITORING V√Ä DEBUGGING

### 1. Spark UI

Sau khi ch·∫°y, truy c·∫≠p Spark UI:
- **Local mode**: http://localhost:4040
- **Standalone**: http://<SPARK_MASTER>:8080
- **YARN**: http://<YARN_RESOURCE_MANAGER>:8088

### 2. Ki·ªÉm tra Logs

```bash
# Xem log real-time
tail -f spark_processor.log

# T√¨m l·ªói
grep -i error spark_processor.log

# T√¨m warnings
grep -i warn spark_processor.log
```

### 3. Ki·ªÉm tra Streaming Query

Trong Spark UI:
- Tab "Streaming" ‚Üí Xem streaming queries
- Ki·ªÉm tra:
  - Input rate > 0 (ƒëang nh·∫≠n d·ªØ li·ªáu)
  - Output rate > 0 (ƒëang g·ª≠i d·ªØ li·ªáu)
  - Processing time
  - Batch duration

### 4. Ki·ªÉm tra Kafka Topics

```bash
# Ki·ªÉm tra input topic
kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic parking-raw-events \
  --from-beginning \
  --max-messages 10

# Ki·ªÉm tra output topic
kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic parking-processed-results \
  --from-beginning \
  --max-messages 10
```

---

## TROUBLESHOOTING

### L·ªói: Cannot connect to Kafka

**Nguy√™n nh√¢n:** 
- Kafka broker kh√¥ng ch·∫°y
- Firewall ch·∫∑n port 9092
- ƒê·ªãa ch·ªâ IP sai

**Gi·∫£i ph√°p:**
```bash
# Ki·ªÉm tra Kafka ƒëang ch·∫°y
ps aux | grep kafka

# Ki·ªÉm tra port
netstat -tuln | grep 9092

# Ki·ªÉm tra k·∫øt n·ªëi
telnet <KAFKA_IP> 9092
```

### L·ªói: Checkpoint location not accessible

**Nguy√™n nh√¢n:**
- Th∆∞ m·ª•c kh√¥ng t·ªìn t·∫°i
- Kh√¥ng c√≥ quy·ªÅn ghi
- Trong cluster mode nh∆∞ng d√πng local path

**Gi·∫£i ph√°p:**
```bash
# Local mode: T·∫°o th∆∞ m·ª•c v√† set quy·ªÅn
mkdir -p /tmp/parking-checkpoint
chmod 777 /tmp/parking-checkpoint

# Cluster mode: T·∫°o tr√™n HDFS
hdfs dfs -mkdir -p /parking-checkpoint
hdfs dfs -chmod 777 /parking-checkpoint
```

### L·ªói: Package not found

**Nguy√™n nh√¢n:**
- Kh√¥ng c√≥ internet ƒë·ªÉ download package
- Repository kh√¥ng accessible

**Gi·∫£i ph√°p:**
- Download JAR th·ªß c√¥ng v√† copy v√†o `$SPARK_HOME/jars/`
- Ho·∫∑c c·∫•u h√¨nh Maven repository n·ªôi b·ªô

### L·ªói: Out of memory

**Nguy√™n nh√¢n:**
- Executor memory qu√° th·∫•p
- Qu√° nhi·ªÅu state ƒë∆∞·ª£c l∆∞u

**Gi·∫£i ph√°p:**
```bash
# TƒÉng executor memory
--executor-memory 4g

# Ho·∫∑c gi·∫£m s·ªë l∆∞·ª£ng xe ƒë·ªìng th·ªùi trong simulator
```

---

## BEST PRACTICES

1. **Lu√¥n d√πng checkpoint location tr√™n shared storage** khi ch·∫°y cluster
2. **Monitor Spark UI** ƒë·ªÉ theo d√µi performance
3. **Log rotation** ƒë·ªÉ tr√°nh log file qu√° l·ªõn
4. **Health check script** ƒë·ªÉ t·ª± ƒë·ªông restart n·∫øu crash
5. **Backup checkpoint** ƒë·ªãnh k·ª≥ (n·∫øu quan tr·ªçng)

---

## K·∫æT LU·∫¨N

‚úÖ **Code Spark ho√†n to√†n s·∫µn s√†ng ch·∫°y tr√™n server b·∫±ng spark-submit**

**ƒêi·ªÉm quan tr·ªçng:**
- ‚úÖ Code ƒë√£ ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ ch·∫°y standalone
- ‚úÖ Checkpoint location c√≥ th·ªÉ config qua argument
- ‚úÖ Kh√¥ng c√≥ hardcode paths
- ‚úÖ Ph√π h·ª£p v·ªõi c·∫£ local v√† cluster mode

**Ch·ªâ c·∫ßn:**
1. ƒê·∫£m b·∫£o checkpoint location ph√π h·ª£p v·ªõi mode (local vs cluster)
2. C·∫•u h√¨nh ƒë√∫ng Kafka bootstrap servers
3. Load ƒë√∫ng Spark packages
4. Monitor qua Spark UI

Ch√∫c b·∫°n deploy th√†nh c√¥ng! üöÄ

